{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZv0uWM6vB96ZJ0sLMkc6O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pradeepsai7/OIBSIP/blob/main/Project_2_Proposal_Level_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cl0FgBGz9Uur",
        "outputId": "3c754cee-df33-49d2-f2b0-18ce1e15c773"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "ROC AUC: 0.8832643656540957\n",
            "PR AUC: 0.5502326534908203\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.94      0.93       343\n",
            "           1       0.60      0.48      0.54        62\n",
            "\n",
            "    accuracy                           0.87       405\n",
            "   macro avg       0.75      0.71      0.73       405\n",
            "weighted avg       0.86      0.87      0.87       405\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, roc_curve, precision_recall_curve, auc\n",
        "import joblib\n",
        "import shap\n",
        "import os\n",
        "\n",
        "df = pd.read_csv(\"ifood_df.csv\")\n",
        "df = df.copy()\n",
        "if 'Response' not in df.columns:\n",
        "    raise SystemExit(\"Target column 'Response' not found\")\n",
        "if 'DtCustomer' in df.columns:\n",
        "    df['DtCustomer'] = pd.to_datetime(df['DtCustomer'], dayfirst=True, errors='coerce')\n",
        "    if df['DtCustomer'].notnull().any():\n",
        "        max_date = df['DtCustomer'].max()\n",
        "        df['CustomerTenureDays'] = (max_date - df['DtCustomer']).dt.days\n",
        "        df['CustomerTenureDays'].fillna(df['CustomerTenureDays'].median(), inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "count_cols = ['Kidhome','Teenhome','NumDealsPurchases','NumCatalogPurchases','NumStorePurchases','NumWebPurchases','NumWebVisitsMonth']\n",
        "for c in count_cols:\n",
        "    if c in df.columns:\n",
        "        df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0).astype(int)\n",
        "spend_cols = [c for c in df.columns if c.startswith('Mnt')]\n",
        "for c in spend_cols:\n",
        "    df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0.0)\n",
        "if 'Income' in df.columns:\n",
        "    df['Income'] = pd.to_numeric(df['Income'], errors='coerce')\n",
        "numeric_cols = df.select_dtypes(include=['int64','float64']).columns.tolist()\n",
        "numeric_cols = [c for c in numeric_cols if c not in ['Response']]\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "drop_cols = []\n",
        "for c in ['DtCustomer','ID','CustomerID','someIDcolumn']:\n",
        "    if c in df.columns:\n",
        "        drop_cols.append(c)\n",
        "df = df.drop(columns=drop_cols, errors='ignore')\n",
        "df.fillna({'Education':'Unknown','Marital':'Unknown'}, inplace=True)\n",
        "df['TotalSpent'] = df[[c for c in spend_cols if c in df.columns]].sum(axis=1)\n",
        "purchase_cols = [c for c in ['NumDealsPurchases','NumCatalogPurchases','NumStorePurchases','NumWebPurchases'] if c in df.columns]\n",
        "df['TotalPurchases'] = df[purchase_cols].sum(axis=1) if purchase_cols else 0\n",
        "df['AvgSpendPerPurchase'] = df['TotalSpent'] / df['TotalPurchases'].replace(0,1)\n",
        "if all(x in df.columns for x in ['AcceptedCmp1','AcceptedCmp2','AcceptedCmp3','AcceptedCmp4','AcceptedCmp5']):\n",
        "    df['AcceptedPrior'] = df[['AcceptedCmp1','AcceptedCmp2','AcceptedCmp3','AcceptedCmp4','AcceptedCmp5']].sum(axis=1)\n",
        "df['HasChildren'] = ((df['Kidhome'] if 'Kidhome' in df.columns else 0) + (df['Teenhome'] if 'Teenhome' in df.columns else 0) > 0).astype(int)\n",
        "df['LogTotalSpent'] = np.log1p(df['TotalSpent'])\n",
        "if 'Income' in df.columns:\n",
        "    df['LogIncome'] = np.log1p(df['Income'].clip(lower=0))\n",
        "features = [c for c in df.columns if c != 'Response']\n",
        "X = df[features].copy()\n",
        "y = df['Response'].astype(int).copy()\n",
        "numeric_features = X.select_dtypes(include=['int64','float64']).columns.tolist()\n",
        "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
        "numeric_transformer = SimpleImputer(strategy='median')\n",
        "categorical_transformer = SimpleImputer(strategy='constant', fill_value='Unknown')\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', numeric_transformer, numeric_features),\n",
        "    ('cat', categorical_transformer, categorical_features)\n",
        "], remainder='drop')\n",
        "X_prep = pd.DataFrame(preprocessor.fit_transform(X))\n",
        "num_names = numeric_features\n",
        "cat_names = categorical_features\n",
        "ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "if len(cat_names) > 0:\n",
        "    ohe.fit(X[cat_names].astype(str))\n",
        "    ohe_cols = list(ohe.get_feature_names_out(cat_names))\n",
        "else:\n",
        "    ohe_cols = []\n",
        "X_num = pd.DataFrame(SimpleImputer(strategy='median').fit_transform(X[num_names]), columns=num_names)\n",
        "if len(cat_names) > 0:\n",
        "    X_cat = pd.DataFrame(ohe.transform(X[cat_names].astype(str)), columns=ohe_cols)\n",
        "else:\n",
        "    X_cat = pd.DataFrame(index=X.index)\n",
        "X_proc = pd.concat([X_num.reset_index(drop=True), X_cat.reset_index(drop=True)], axis=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_proc, y, test_size=0.2, stratify=y, random_state=42)\n",
        "sm = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
        "scaler = StandardScaler()\n",
        "X_train_res = pd.DataFrame(scaler.fit_transform(X_train_res), columns=X_train_res.columns)\n",
        "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
        "rf = RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=-1)\n",
        "pipeline = ImbPipeline([('model', rf)])\n",
        "param_dist = {\n",
        "    'model__n_estimators':[100,200,400],\n",
        "    'model__max_depth':[None,8,16,24],\n",
        "    'model__min_samples_split':[2,5,10],\n",
        "    'model__min_samples_leaf':[1,2,4],\n",
        "    'model__max_features':['sqrt','log2',0.2,0.5]\n",
        "}\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "rs = RandomizedSearchCV(pipeline, param_distributions=param_dist, n_iter=20, scoring='roc_auc', cv=cv, n_jobs=-1, random_state=42, verbose=1)\n",
        "rs.fit(X_train_res, y_train_res)\n",
        "best = rs.best_estimator_\n",
        "y_pred = best.predict(X_test_scaled)\n",
        "if hasattr(best, \"predict_proba\"):\n",
        "    y_proba = best.predict_proba(X_test_scaled)[:,1]\n",
        "else:\n",
        "    y_proba = best.decision_function(X_test_scaled)\n",
        "report = classification_report(y_test, y_pred, output_dict=False)\n",
        "roc_auc = roc_auc_score(y_test, y_proba)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "os.makedirs(\"eda\", exist_ok=True)\n",
        "plt.figure(figsize=(6,6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.savefig(\"eda/confusion_matrix.png\")\n",
        "plt.close()\n",
        "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.4f}\")\n",
        "plt.plot([0,1],[0,1],'--')\n",
        "plt.xlabel(\"FPR\")\n",
        "plt.ylabel(\"TPR\")\n",
        "plt.title(\"ROC Curve\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.savefig(\"eda/roc_curve.png\")\n",
        "plt.close()\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
        "pr_auc = auc(recall, precision)\n",
        "plt.figure()\n",
        "plt.plot(recall, precision, label=f\"PR AUC = {pr_auc:.4f}\")\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curve\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(\"eda/pr_curve.png\")\n",
        "plt.close()\n",
        "fi = None\n",
        "try:\n",
        "    model_obj = best.named_steps['model']\n",
        "    importances = model_obj.feature_importances_\n",
        "    feat_names = X_train_res.columns\n",
        "    fi = pd.Series(importances, index=feat_names).sort_values(ascending=False)\n",
        "    fi.head(30).to_csv(\"eda/feature_importances.csv\")\n",
        "except Exception:\n",
        "    pass\n",
        "try:\n",
        "    explainer = shap.TreeExplainer(model_obj)\n",
        "    shap_values = explainer.shap_values(X_test_scaled)\n",
        "    shap.summary_plot(shap_values, X_test_scaled, show=False)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"eda/shap_summary.png\")\n",
        "    plt.close()\n",
        "except Exception:\n",
        "    pass\n",
        "joblib.dump({'pipeline':best, 'scaler':scaler, 'ohe':ohe, 'num_features':num_names, 'cat_features':cat_names, 'feature_columns': X_proc.columns.tolist()}, \"best_pipeline.pkl\")\n",
        "with open(\"report.txt\", \"w\") as f:\n",
        "    f.write(\"Classification Report\\n\")\n",
        "    f.write(report + \"\\n\\n\")\n",
        "    f.write(f\"ROC AUC: {roc_auc}\\n\")\n",
        "    if fi is not None:\n",
        "        f.write(\"\\nTop feature importances:\\n\")\n",
        "        f.write(fi.head(30).to_string())\n",
        "print(\"ROC AUC:\", roc_auc)\n",
        "print(\"PR AUC:\", pr_auc)\n",
        "print(report)"
      ]
    }
  ]
}